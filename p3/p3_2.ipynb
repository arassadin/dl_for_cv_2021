{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJ4aT3ch181r"
   },
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqf8hI6Dx49R"
   },
   "outputs": [],
   "source": [
    "!pip install fiftyone==0.14.2 \n",
    "!pip install ipywidgets>=7.5\n",
    "!pip install tensorflow torch torchvision umap-learn\n",
    "!pip install albumentations==1.1.0\n",
    "!pip install opencv-python==4.5.5.62 \n",
    "!pip install opencv-python-headless==4.5.4.60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pxbCgGL2Aqk"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSmPOiiLbPyU"
   },
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import fiftyone.utils.coco as fouc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImF5VVdYbX64"
   },
   "outputs": [],
   "source": [
    "classes_list = [\"Cat\", \"Dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZwRIQHoUVhP"
   },
   "outputs": [],
   "source": [
    "train_dataset = foz.load_zoo_dataset(\n",
    "    \"open-images-v6\", \n",
    "    split=\"train\", \n",
    "    label_types=[\"detections\"], \n",
    "    classes=classes_list,\n",
    "    max_samples=2000,\n",
    "    seed=51,\n",
    "    shuffle=True,\n",
    "    dataset_name=\"cat_dog_train\"\n",
    ")\n",
    "train_dataset.persistent = True\n",
    "# Using `persistent` property is useful when working in a local runtime session. \n",
    "# Using Colab hosted runtime you will need to download the data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXe0AsPJUbZ7"
   },
   "outputs": [],
   "source": [
    "test_dataset = foz.load_zoo_dataset(\n",
    "    \"open-images-v6\", \n",
    "    split=\"test\", \n",
    "    label_types=[\"detections\"], \n",
    "    classes=classes_list,\n",
    "    max_samples=500,\n",
    "    seed=51,\n",
    "    shuffle=True,\n",
    "    dataset_name=\"cat_dog_test\",\n",
    ")\n",
    "test_dataset.persistent = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Dc7fBV1UbXL"
   },
   "outputs": [],
   "source": [
    "val_dataset = foz.load_zoo_dataset(\n",
    "    \"open-images-v6\", \n",
    "    split=\"validation\", \n",
    "    label_types=[\"detections\"], \n",
    "    classes=classes_list,\n",
    "    seed=51,\n",
    "    max_samples=500,\n",
    "    shuffle=True,\n",
    "    dataset_name=\"cat_dog_val\",\n",
    ")\n",
    "val_dataset.persistent = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NokactU_0OX7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vnkV4KUAYQPi"
   },
   "outputs": [],
   "source": [
    "print(fo.list_datasets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UbtIGAjT1Tp"
   },
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n",
    "\n",
    "train_dataset = fo.load_dataset(\"cat_dog_train\").filter_labels( \"detections\", F(\"label\").is_in(classes_list))\n",
    "test_dataset = fo.load_dataset(\"cat_dog_test\").filter_labels( \"detections\", F(\"label\").is_in(classes_list))\n",
    "val_dataset = fo.load_dataset(\"cat_dog_val\").filter_labels( \"detections\", F(\"label\").is_in(classes_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zS-hdRxQbYvv"
   },
   "outputs": [],
   "source": [
    "len(train_dataset), len(test_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFXEn_XwWPOf"
   },
   "outputs": [],
   "source": [
    "session = fo.launch_app(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdzVZDwR2EsO"
   },
   "source": [
    "# Prepare Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEwTXuPdbYrJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wnXwZF0gbYo-"
   },
   "outputs": [],
   "source": [
    "class FiftyOneTorchDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"A class to construct a PyTorch dataset from a FiftyOne dataset.\n",
    "    \n",
    "    Args:\n",
    "        fiftyone_dataset: a FiftyOne dataset or view that will be used for training or testing\n",
    "        transforms (None): a list of PyTorch transforms to apply to images and targets when loading\n",
    "        gt_field (\"ground_truth\"): the name of the field in fiftyone_dataset that contains the \n",
    "            desired labels to load\n",
    "        classes (None): a list of class strings that are used to define the mapping between\n",
    "            class names and indices. If None, it will use all classes present in the given fiftyone_dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        fiftyone_dataset,\n",
    "        transforms=None,\n",
    "        gt_field=\"detections\",\n",
    "        classes=None,\n",
    "    ):\n",
    "        self.samples = fiftyone_dataset\n",
    "        self.transforms = transforms\n",
    "        self.gt_field = gt_field\n",
    "\n",
    "        self.img_paths = self.samples.values(\"filepath\")\n",
    "\n",
    "        self.classes = classes\n",
    "        if not self.classes:\n",
    "            # Get list of distinct labels that exist in the view\n",
    "            self.classes = self.samples.distinct(\n",
    "                \"%s.detections.label\" % gt_field\n",
    "            )\n",
    "\n",
    "        if self.classes[0] != \"background\":\n",
    "            self.classes = [\"background\"] + self.classes\n",
    "\n",
    "        self.labels_map_rev = {c: i for i, c in enumerate(self.classes)}\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # reading the images and converting them to correct color  \n",
    "        img_path = self.img_paths[idx]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # prepairing target\n",
    "        sample = self.samples[img_path]   \n",
    "        # cv2 image gives size as height x width    \n",
    "        wt = img.shape[1]\n",
    "        ht = img.shape[0]\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        detections = sample[self.gt_field].detections\n",
    "        for det in detections:\n",
    "            if det.label not in self.classes:\n",
    "                continue\n",
    "                \n",
    "            category_id = self.labels_map_rev[det.label]\n",
    "            x, y, w, h = det[\"bounding_box\"]\n",
    "            boxes.append([x * wt, y * ht, (x + w) * wt, (y + h) * ht])\n",
    "            labels.append(category_id)\n",
    "\n",
    "        \n",
    "        # applying augmentations\n",
    "        if self.transforms is not None:\n",
    "            transformed = self.transforms(image=img,bboxes=boxes, category_ids=labels)\n",
    "            img = transformed[\"image\"]\n",
    "            boxes = transformed[\"bboxes\"]\n",
    "            labels = transformed[\"category_ids\"]\n",
    "\n",
    "        # convert boxes into a torch.Tensor                \n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)                \n",
    "            \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        target[\"image_id\"] = torch.as_tensor([idx])\n",
    "\n",
    "        # getting the areas of the boxes\n",
    "        target[\"area\"] = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "\n",
    "        # suppose all instances are not crowd\n",
    "        target[\"iscrowd\"] = torch.zeros((boxes.shape[0],), dtype=torch.int64)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def get_classes(self):\n",
    "        return self.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "149s708q2IXO"
   },
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ulh9noUzbYmO"
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DeBJ294bYja"
   },
   "outputs": [],
   "source": [
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.LongestMaxSize(320),\n",
    "        A.PadIfNeeded(min_height=320, min_width=320, border_mode=0),\n",
    "        A.RandomSizedBBoxSafeCrop(width=300, height=300, erosion_rate=0.1),\n",
    "     \n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.3),\n",
    "        A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.3),\n",
    "        A.ToFloat(max_value=255, p=1, always_apply=True),\n",
    "\n",
    "        ToTensorV2(p=1.0)\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format='pascal_voc', label_fields=['category_ids']),\n",
    ")\n",
    "\n",
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.LongestMaxSize(300),\n",
    "        A.PadIfNeeded(min_height=300, min_width=300, border_mode=0),\n",
    "        A.ToFloat(max_value=255, p=1, always_apply=True),\n",
    "\n",
    "        ToTensorV2(p=1.0)\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format='pascal_voc', label_fields=['category_ids']),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVeRFwbw2Uye"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFuR5vY_fAtJ"
   },
   "outputs": [],
   "source": [
    "torch_dataset = FiftyOneTorchDataset(train_dataset, train_transform, \n",
    "        classes=classes_list, gt_field=\"detections\")\n",
    "torch_dataset_test = FiftyOneTorchDataset(test_dataset, test_transform, \n",
    "        classes=classes_list, gt_field=\"detections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aay1PwMvfAq7"
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.ssd300_vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fEq2OenKfAou"
   },
   "outputs": [],
   "source": [
    "from torchvision.models.detection.ssd import SSDHead\n",
    "in_channels = [x.in_channels for x in model.head.classification_head.module_list]\n",
    "head = SSDHead(in_channels=in_channels , num_anchors=[4,6,6,6,4,4] , num_classes=len(classes_list)+1)\n",
    "model.head = head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8oqbjx8LfAkw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyg_6XsyDKj0"
   },
   "outputs": [],
   "source": [
    "class Averager:\n",
    "    def __init__(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "    def send(self, value):\n",
    "        self.current_total += value\n",
    "        self.iterations += 1\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        if self.iterations == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.0 * self.current_total / self.iterations\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ia2vWAb7iPz-"
   },
   "outputs": [],
   "source": [
    "bs = 16\n",
    "test_bs = 1\n",
    "num_epochs = 50\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zN5v8FADfAgS"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6w0ssVffAd2"
   },
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    torch_dataset, batch_size=bs, shuffle=True, num_workers=2,\n",
    "    collate_fn=collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    torch_dataset_test, batch_size=test_bs, shuffle=False, num_workers=2,\n",
    "    collate_fn=collate_fn)\n",
    "\n",
    "# train on the GPU or on the CPU, if a GPU is not available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"Using device %s\" % device)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=learning_rate,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# and a learning rate scheduler\n",
    "lr_scheduler = None\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "#                                                 step_size=3,\n",
    "#                                                 gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkKIiz3MqJjw"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/cat_dog_experiment_1_ssd_lr5e-4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXxEldg9tjK4"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9l3VpAO0p7W"
   },
   "outputs": [],
   "source": [
    "# Clone TorchVision repo and copy helper files\n",
    "!git clone https://github.com/pytorch/vision.git\n",
    "%cd vision\n",
    "!git checkout v0.3.0\n",
    "%cd ..\n",
    "!cp vision/references/detection/utils.py ./\n",
    "!cp vision/references/detection/transforms.py ./\n",
    "!cp vision/references/detection/coco_eval.py ./\n",
    "!cp vision/references/detection/engine.py ./\n",
    "!cp vision/references/detection/coco_utils.py ./\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-GxeBc4qEcVs"
   },
   "outputs": [],
   "source": [
    "from engine import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2IkbzSCChy0I"
   },
   "outputs": [],
   "source": [
    "loss_hist = Averager()\n",
    "itr = 1\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "\n",
    "best_metric = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    model.train()\n",
    "    loss_hist.reset()\n",
    "    with fo.ProgressBar() as pb:\n",
    "        for images, targets in pb(data_loader):\n",
    "        \n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            loss_value = losses.item()\n",
    "            loss_hist.send(loss_value)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            writer.add_scalar('Loss_iter/train', loss_value, itr)\n",
    "\n",
    "            itr += 1\n",
    "        \n",
    "        # update the learning rate\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        writer.add_scalar('Loss/train', loss_hist.value, epoch)\n",
    "\n",
    "    #Evaluation\n",
    "    cc_ev = evaluate(model, data_loader_test, device=device)\n",
    "    current_metric = cc_ev.coco_eval[\"bbox\"].stats[0]\n",
    "    writer.add_scalar('mAP/test', current_metric, epoch)\n",
    "\n",
    "    #Saving the best weights\n",
    "    if current_metric > best_metric:\n",
    "        best_metric = current_metric\n",
    "        torch.save(model.state_dict(), \"best_weights.pth\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRMEJZ9TX4uI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CZ6G1C813u7"
   },
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKmfEkaqX4nz"
   },
   "outputs": [],
   "source": [
    "import fiftyone.utils.coco as fouc\n",
    "\n",
    "def convert_torch_predictions(preds, det_id, s_id, w, h, classes):\n",
    "    # Convert the outputs of the torch model into a FiftyOne Detections object\n",
    "    dets = []\n",
    "    scale = max(w, h)\n",
    "    shift = abs(w - h) / 2\n",
    "    if w > h:\n",
    "        shift = np.tile([0,1], 2) * shift\n",
    "    else:\n",
    "        shift = np.tile([1,0], 2) * shift\n",
    "        \n",
    "    for bbox, label, score in zip(\n",
    "        preds[\"boxes\"].cpu().detach().numpy(), \n",
    "        preds[\"labels\"].cpu().detach().numpy(), \n",
    "        preds[\"scores\"].cpu().detach().numpy()\n",
    "    ):\n",
    "\n",
    "        # Parse prediction into FiftyOne Detection object\n",
    "        x0, y0, x1, y1 = bbox / 300 * scale - shift\n",
    "        coco_obj = fouc.COCOObject(det_id, s_id, int(label), [x0, y0, x1-x0, y1-y0])\n",
    "        det = coco_obj.to_detection((w,h), classes)\n",
    "        det[\"confidence\"] = float(score)\n",
    "        dets.append(det)\n",
    "        det_id += 1\n",
    "        \n",
    "    detections = fo.Detections(detections=dets)\n",
    "        \n",
    "    return detections, det_id\n",
    "\n",
    "def add_detections(model, torch_dataset, view, field_name=\"predictions\"):\n",
    "    # Run inference on a dataset and add results to FiftyOne\n",
    "    torch.set_num_threads(1)\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    print(\"Using device %s\" % device)\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    image_paths = torch_dataset.img_paths\n",
    "    classes = torch_dataset.classes\n",
    "    det_id = 0\n",
    "    \n",
    "    with fo.ProgressBar() as pb:\n",
    "        for img, targets in pb(torch_dataset):\n",
    "            # Get FiftyOne sample indexed by unique image filepath\n",
    "            img_id = int(targets[\"image_id\"][0])\n",
    "            img_path = image_paths[img_id]\n",
    "            sample = view[img_path]\n",
    "            s_id = sample.id\n",
    "            w, h = 0, 0\n",
    "            if sample.metadata is None:\n",
    "                img_raw = cv2.imread(img_path)\n",
    "                h, w, _ = img_raw.shape\n",
    "            else:\n",
    "                w = sample.metadata[\"width\"]\n",
    "                h = sample.metadata[\"height\"]\n",
    "            \n",
    "            # Inference\n",
    "            preds = model(img.unsqueeze(0).to(device))[0]\n",
    "            \n",
    "            detections, det_id = convert_torch_predictions(\n",
    "                preds, \n",
    "                det_id, \n",
    "                s_id, \n",
    "                w, \n",
    "                h, \n",
    "                classes,\n",
    "            )\n",
    "            \n",
    "            sample[field_name] = detections\n",
    "            sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V61N-eQeI-VJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_S4ATHV7X_qD"
   },
   "outputs": [],
   "source": [
    "torch_dataset_val = FiftyOneTorchDataset(val_dataset, test_transform, \n",
    "        classes=classes_list, gt_field=\"detections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56OmyqW4X_mp"
   },
   "outputs": [],
   "source": [
    "add_detections(model, torch_dataset_val, val_dataset, field_name=\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DhAP1B1pHFt6"
   },
   "outputs": [],
   "source": [
    "metric_view = val_dataset.filter_labels(\"predictions\", F(\"confidence\") > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQsbfpx2YE3V"
   },
   "outputs": [],
   "source": [
    "results = fo.evaluate_detections(\n",
    "    metric_view,\n",
    "    \"predictions\",\n",
    "    gt_field=\"detections\", \n",
    "    classes=classes_list, \n",
    "    eval_key=\"eval\", \n",
    "    compute_mAP=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_piDKF8YEv3"
   },
   "outputs": [],
   "source": [
    "results.mAP(), results.metrics() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtXftPhW1P_s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "custom_train_loop.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
